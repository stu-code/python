{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import requests\n",
    "import saspy\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "from dateutil import parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_remote_zip(url):\n",
    "    response = requests.get(url, stream=True)\n",
    "    zip_file = ZipFile(BytesIO(response.content))\n",
    "    return zip_file\n",
    "    \n",
    "zip_hr       = read_remote_zip(\"https://github.com/stu-code/viz/raw/refs/heads/main/snowboarding/data/biometrics/hr/hr.zip\")\n",
    "zip_hr_var   = read_remote_zip(\"https://github.com/stu-code/viz/raw/refs/heads/main/snowboarding/data/biometrics/hr_variability/hr_variability.zip\")\n",
    "zip_spo2     = read_remote_zip(\"https://github.com/stu-code/viz/raw/refs/heads/main/snowboarding/data/biometrics/spo2/spo2.zip\")\n",
    "zip_spo2_var = read_remote_zip(\"https://github.com/stu-code/viz/raw/refs/heads/main/snowboarding/data/biometrics/spo2_variability/spo2_variability.zip\")\n",
    "zip_gps      = read_remote_zip(\"https://github.com/stu-code/viz/raw/refs/heads/main/snowboarding/data/gps/gps.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Heartrate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list  = []\n",
    "    \n",
    "for json_file in zip_hr.namelist():\n",
    "    with zip_hr.open(json_file) as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    df = pd.json_normalize(data, sep='_')\n",
    "\n",
    "    df.columns = (\n",
    "        df.columns.str.lower()\n",
    "                  .str.replace('value_', '')\n",
    "                  .str.replace('datetime', 'timestamp')\n",
    "    )\n",
    "    \n",
    "    # Convert to datetime and from UTC to Mountain Time\n",
    "    df['timestamp'] = ( \n",
    "        pd.to_datetime(df['timestamp'], format='%m/%d/%y %H:%M:%S', utc=True)\n",
    "          .dt.tz_convert('US/Mountain')\n",
    "          .dt.tz_localize(None)\n",
    "    )\n",
    "    \n",
    "    df_list.append(df)\n",
    "        \n",
    "df_hr = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Biometric CSV Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stsztu\\AppData\\Local\\Temp\\ipykernel_3164\\1981936932.py:6: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(f, parse_dates=['timestamp'])\n",
      "C:\\Users\\stsztu\\AppData\\Local\\Temp\\ipykernel_3164\\1981936932.py:6: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(f, parse_dates=['timestamp'])\n",
      "C:\\Users\\stsztu\\AppData\\Local\\Temp\\ipykernel_3164\\1981936932.py:6: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(f, parse_dates=['timestamp'])\n",
      "C:\\Users\\stsztu\\AppData\\Local\\Temp\\ipykernel_3164\\1981936932.py:6: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(f, parse_dates=['timestamp'])\n",
      "C:\\Users\\stsztu\\AppData\\Local\\Temp\\ipykernel_3164\\1981936932.py:6: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(f, parse_dates=['timestamp'])\n",
      "C:\\Users\\stsztu\\AppData\\Local\\Temp\\ipykernel_3164\\1981936932.py:6: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(f, parse_dates=['timestamp'])\n"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "\n",
    "def read_bio_csv(zip_file):    \n",
    "    for csv_file in zip_file.namelist():\n",
    "        with zip_file.open(csv_file) as f:\n",
    "            df = pd.read_csv(f, parse_dates=['timestamp'])\n",
    "            \n",
    "        df_list.append(df)\n",
    "        \n",
    "    return pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "df_hr_var   = read_bio_csv(zip_hr_var)\n",
    "df_spo2     = read_bio_csv(zip_spo2)\n",
    "df_spo2_var = read_bio_csv(zip_spo2_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read GPS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Read GPS data in GPX format without needing to import a separate GPX \n",
    "    package. GPX data looks like this:\n",
    "        \n",
    "    <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "    <gpx xmlns=\"http://www.topografix.com/GPX/1/1\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:gte=\"http://www.gpstrackeditor.com/xmlschemas/General/1\" xsi:schemaLocation=\"http://www.topografix.com/GPX/1/1 http://www.topografix.com/GPX/1/1/gpx.xsd\" version=\"1.1\" creator=\"Slopes for Android - http://getslopes.com\">\n",
    "      <trk>\n",
    "        <name>Jan 25, 2024 - Keystone Resort</name>\n",
    "        <trkseg>\n",
    "          <trkpt lat=\"39.605675\" lon=\"-105.941414\">\n",
    "            <ele>2856.891977</ele>\n",
    "            <time>2024-01-25T09:13:52.453-07:00</time>\n",
    "            <hdop>19</hdop>\n",
    "            <vdop>4</vdop>\n",
    "            <extensions>\n",
    "              <gte:gps speed=\"1.317580\" azimuth=\"212.300003\"/>\n",
    "            </extensions>\n",
    "          </trkpt>\n",
    "       </trkseg>\n",
    "      </trk>\n",
    "    </gpx>\n",
    "    \n",
    "    There are two namespaces we need to use:\n",
    "        1. The gpx namespace: http://www.topografix.com/GPX/1/1\n",
    "        2. The gte namespace http://www.gpstrackeditor.com/xmlschemas/General/1\n",
    "        \n",
    "    The gte namespace is used to extract gps and azimuth data from the \n",
    "    <extensions> tag\n",
    "'''\n",
    "gpx_namespace = '{http://www.topografix.com/GPX/1/1}'\n",
    "gte_namespace = '{http://www.gpstrackeditor.com/xmlschemas/General/1}'\n",
    "    \n",
    "clean_data = []\n",
    "file_list  = [file_name for file_name in zip_gps.namelist() if file_name.endswith(\".gpx\")]\n",
    "    \n",
    "for gpx_file in file_list:\n",
    "    with zip_gps.open(gpx_file) as f:\n",
    "        raw_data = f.read()\n",
    "            \n",
    "    # ET.parse expects an actual file, so BytesIO makes it behave like a file\n",
    "    root = ET.parse(BytesIO(raw_data))\n",
    "        \n",
    "    for trkpt in root.findall(f'.//{gpx_namespace}trkpt'):\n",
    "        row = {\n",
    "                \"timestamp\":  parser.parse(trkpt.find(f'{gpx_namespace}time').text, ignoretz=True),\n",
    "                \"lat\":       float(trkpt.get(\"lat\")),\n",
    "                \"lon\":       float(trkpt.get(\"lon\")),\n",
    "                \"elevation\": float(trkpt.find(f'{gpx_namespace}ele').text),\n",
    "                \"speed\":     float(trkpt.find(f'.//{gpx_namespace}extensions/{gte_namespace}gps').get(\"speed\")),\n",
    "                \"azimuth\":   float(trkpt.find(f'.//{gpx_namespace}extensions/{gte_namespace}gps').get(\"azimuth\"))\n",
    "              }\n",
    "        \n",
    "        clean_data.append(row)\n",
    "\n",
    "df_gps = pd.DataFrame(clean_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read GPS Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in GPS metadata. This will help us more easily define runs and lifts\n",
    "# and also give us some additonal information if we want to use it\n",
    "   \n",
    "df_list   = []\n",
    "file_list = [file_name for file_name in zip_gps.namelist() if file_name.endswith(\".slopes\")]\n",
    "    \n",
    "# .slopes files are just zip files with some CSVs and XML metadata.\n",
    "# We just want to read Metadata.xml\n",
    "for slopes_file in file_list:\n",
    "    with zip_gps.open(slopes_file) as f:\n",
    "        raw_data = f.read()\n",
    "\n",
    "    with ZipFile(BytesIO(raw_data), 'r') as zip_file:\n",
    "        with zip_file.open('Metadata.xml') as xml_file:\n",
    "            df = pd.read_xml(xml_file, parser='etree', xpath='.//Action')\n",
    "            \n",
    "    # Convert start/end to datetimes without the timezone\n",
    "    df[['start', 'end']] = df[['start', 'end']].map(lambda x: parser.parse(x, ignoretz=True))\n",
    "\n",
    "    # Get datepart (for later processing)\n",
    "    df['date'] = df['start'].dt.date\n",
    "    df_list.append(df)\n",
    "        \n",
    "# Final GPS metadata dataframe \n",
    "df_gps_meta = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAS server started using Context SAS Studio compute context with SESSION_ID=2a670fe4-20e9-4455-89d2-7793ac2370d7-ses0000\n"
     ]
    }
   ],
   "source": [
    "access_token = open(r\"C:\\Users\\stsztu\\casconfig\\access_token.txt\", 'r')\n",
    "\n",
    "sas = saspy.SASsession(\n",
    "    cfgname='httpsviya',  \n",
    "    url=\"https://create.demo.sas.com\",\n",
    "    authtoken=access_token.read(), \n",
    "    cafile=r\"C:\\Users\\stsztu\\casconfig\\demo-rootCA-Intermidiates_4CLI.pem\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Libref  = WORK\n",
       "Table   = gps_meta\n",
       "Dsopts  = {}\n",
       "Results = Pandas"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sas.df2sd(df_hr, 'heartrate')\n",
    "sas.df2sd(df_hr_var, 'heartrate_variability')\n",
    "sas.df2sd(df_spo2, 'spo2')\n",
    "sas.df2sd(df_spo2, 'spo2_variability')\n",
    "sas.df2sd(df_gps, 'gps')\n",
    "sas.df2sd(df_gps_meta, 'gps_meta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LOG': \"337707  ods listing close;ods html5 (id=saspy_internal) options(bitmap_mode='inline') device=svg style=HTMLBlue; ods graphics on /\\n337707! outputfmt=png;\\nNOTE: Writing HTML5(SASPY_INTERNAL) Body file: sashtml2.htm\\n337708  \\n337709  \\n337710  \\n337711  data heartrate;\\n337712      set heartrate;\\n337713  \\n337714      /* Convert to MT */\\n337715      if('25JAN2024'd LE datepart(timestamp) LE '28JAN2024'd)\\n337716          then timestamp = intnx('hour', timestamp, -7, 'S')\\n337717      ;\\n337718  \\n337719      /* Convert to ET */\\n337720      else if('23FEB2024'd LE datepart(timestamp) LE '24FEB2024'd)\\n337721          then timestamp = intnx('hour', timestamp, -5, 'S')\\n337722      ;\\n337723  run;\\n\\nNOTE: There were 59429 observations read from the data set WORK.HEARTRATE.\\nNOTE: The data set WORK.HEARTRATE has 59429 observations and 3 variables.\\nNOTE: DATA statement used (Total process time):\\n      real time           0.01 seconds\\n      cpu time            0.02 seconds\\n      \\n\\n337724  \\n337725  \\n337726  ods html5 (id=saspy_internal) close;ods listing;\\n337727  \\n\\n\",\n",
       " 'LST': ''}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sas.submit(code=\n",
    "'''\n",
    "\n",
    "data heartrate;\n",
    "    set heartrate;\n",
    "\n",
    "    /* Convert to MT */\n",
    "    if('25JAN2024'd LE datepart(timestamp) LE '28JAN2024'd)\n",
    "        then timestamp = intnx('hour', timestamp, -7, 'S')\n",
    "    ;\n",
    "\n",
    "    /* Convert to ET */\n",
    "    else if('23FEB2024'd LE datepart(timestamp) LE '24FEB2024'd)\n",
    "        then timestamp = intnx('hour', timestamp, -5, 'S')\n",
    "    ;\n",
    "run;\n",
    "\n",
    "'''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LOG': [{'line': \"337758  ods listing close;ods html5 (id=saspy_internal) options(bitmap_mode='inline') device=svg style=HTMLBlue; ods graphics on /\",\n",
       "   'type': 'source',\n",
       "   'version': 1},\n",
       "  {'line': '337758! outputfmt=png;', 'type': 'source', 'version': 1},\n",
       "  {'line': 'NOTE: Writing HTML5(SASPY_INTERNAL) Body file: sashtml4.htm',\n",
       "   'type': 'note',\n",
       "   'version': 1},\n",
       "  {'line': '337759  ', 'type': 'source', 'version': 1},\n",
       "  {'line': '337760  ', 'type': 'source', 'version': 1},\n",
       "  {'line': '337761  ', 'type': 'source', 'version': 1},\n",
       "  {'line': '337762  data gps_meta;', 'type': 'source', 'version': 1},\n",
       "  {'line': '337763      set gps_meta;', 'type': 'source', 'version': 1},\n",
       "  {'line': '337764      date = datepart(start);',\n",
       "   'type': 'source',\n",
       "   'version': 1},\n",
       "  {'line': '337765  ', 'type': 'source', 'version': 1},\n",
       "  {'line': '337766      format date date9.;', 'type': 'source', 'version': 1},\n",
       "  {'line': '337767  run;', 'type': 'source', 'version': 1},\n",
       "  {'line': '', 'type': 'note', 'version': 1},\n",
       "  {'line': 'NOTE: There were 173 observations read from the data set WORK.GPS_META.',\n",
       "   'type': 'note',\n",
       "   'version': 1},\n",
       "  {'line': 'NOTE: The data set WORK.GPS_META has 173 observations and 23 variables.',\n",
       "   'type': 'note',\n",
       "   'version': 1},\n",
       "  {'line': 'NOTE: DATA statement used (Total process time):',\n",
       "   'type': 'note',\n",
       "   'version': 1},\n",
       "  {'line': '      real time           0.00 seconds',\n",
       "   'type': 'note',\n",
       "   'version': 1},\n",
       "  {'line': '      cpu time            0.01 seconds',\n",
       "   'type': 'note',\n",
       "   'version': 1},\n",
       "  {'line': '      ', 'type': 'note', 'version': 1},\n",
       "  {'line': '', 'type': 'note', 'version': 1},\n",
       "  {'line': '337768  ', 'type': 'source', 'version': 1},\n",
       "  {'line': '337769  proc sort data=gps_meta;', 'type': 'source', 'version': 1},\n",
       "  {'line': '337770      by date type start;', 'type': 'source', 'version': 1},\n",
       "  {'line': '337771  run;', 'type': 'source', 'version': 1},\n",
       "  {'line': '', 'type': 'note', 'version': 1},\n",
       "  {'line': 'NOTE: There were 173 observations read from the data set WORK.GPS_META.',\n",
       "   'type': 'note',\n",
       "   'version': 1},\n",
       "  {'line': 'NOTE: The data set WORK.GPS_META has 173 observations and 23 variables.',\n",
       "   'type': 'note',\n",
       "   'version': 1},\n",
       "  {'line': 'NOTE: PROCEDURE SORT used (Total process time):',\n",
       "   'type': 'note',\n",
       "   'version': 1},\n",
       "  {'line': '      real time           0.00 seconds',\n",
       "   'type': 'note',\n",
       "   'version': 1},\n",
       "  {'line': '      cpu time            0.00 seconds',\n",
       "   'type': 'note',\n",
       "   'version': 1},\n",
       "  {'line': '      ', 'type': 'note', 'version': 1},\n",
       "  {'line': '', 'type': 'note', 'version': 1},\n",
       "  {'line': '337772  ', 'type': 'source', 'version': 1},\n",
       "  {'line': '337773  /* Identify run numbers */',\n",
       "   'type': 'source',\n",
       "   'version': 1},\n",
       "  {'line': '337774  data gps_meta;', 'type': 'source', 'version': 1},\n",
       "  {'line': '337775      set gps_meta;', 'type': 'source', 'version': 1},\n",
       "  {'line': '337776      by date type start;', 'type': 'source', 'version': 1},\n",
       "  {'line': '337777  ', 'type': 'source', 'version': 1},\n",
       "  {'line': '337778      if(first.type) then call missing(nbr);',\n",
       "   'type': 'source',\n",
       "   'version': 1},\n",
       "  {'line': '337779  ', 'type': 'source', 'version': 1},\n",
       "  {'line': '337780      nbr+1;', 'type': 'source', 'version': 1},\n",
       "  {'line': '337781  ', 'type': 'source', 'version': 1},\n",
       "  {'line': '337782      drop date;', 'type': 'source', 'version': 1},\n",
       "  {'line': '337783  run;', 'type': 'source', 'version': 1},\n",
       "  {'line': '', 'type': 'note', 'version': 1},\n",
       "  {'line': 'NOTE: There were 173 observations read from the data set WORK.GPS_META.',\n",
       "   'type': 'note',\n",
       "   'version': 1},\n",
       "  {'line': 'NOTE: The data set WORK.GPS_META has 173 observations and 22 variables.',\n",
       "   'type': 'note',\n",
       "   'version': 1},\n",
       "  {'line': 'NOTE: DATA statement used (Total process time):',\n",
       "   'type': 'note',\n",
       "   'version': 1},\n",
       "  {'line': '      real time           0.00 seconds',\n",
       "   'type': 'note',\n",
       "   'version': 1},\n",
       "  {'line': '      cpu time            0.01 seconds',\n",
       "   'type': 'note',\n",
       "   'version': 1},\n",
       "  {'line': '      ', 'type': 'note', 'version': 1},\n",
       "  {'line': '', 'type': 'note', 'version': 1},\n",
       "  {'line': '337784  ', 'type': 'source', 'version': 1},\n",
       "  {'line': '337785  ', 'type': 'source', 'version': 1},\n",
       "  {'line': '337786  ods html5 (id=saspy_internal) close;ods listing;',\n",
       "   'type': 'source',\n",
       "   'version': 1},\n",
       "  {'line': '337787  ', 'type': 'source', 'version': 1},\n",
       "  {'line': '', 'type': 'note', 'version': 1}],\n",
       " 'LST': ''}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sas.submit(loglines=True, code=\n",
    "'''\n",
    "\n",
    "data gps_meta;\n",
    "    set gps_meta;\n",
    "    date = datepart(start);\n",
    "\n",
    "    format date date9.;\n",
    "run;\n",
    "\n",
    "proc sort data=gps_meta;\n",
    "    by date type start;\n",
    "run;\n",
    "\n",
    "/* Identify run numbers */\n",
    "data gps_meta;\n",
    "    set gps_meta;\n",
    "    by date type start;\n",
    "\n",
    "    if(first.type) then call missing(nbr);\n",
    "        \n",
    "    nbr+1;\n",
    "           \n",
    "    drop date;\n",
    "run;\n",
    "\n",
    "'''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LOG': \"337788  ods listing close;ods html5 (id=saspy_internal) options(bitmap_mode='inline') device=svg style=HTMLBlue; ods graphics on /\\n337788! outputfmt=png;\\nNOTE: Writing HTML5(SASPY_INTERNAL) Body file: sashtml5.htm\\n337789  \\n337790  \\n337791  \\n337792  /* Fuzzy merge GPS with heartrate data */\\n337793  proc sql;\\n337794      create table _snowboarding_gps_hr(drop=dif) as\\n337795          select round(gps.timestamp) as timestamp format=datetime.2\\n337796               , datepart(gps.timestamp) as date format=date9.\\n337797               , gps.lat\\n337798               , gps.lon\\n337799               , round(gps.elevation)*3.28084 as elevation\\n337800               , round(gps.speed, .1) as speed\\n337801               , hr.bpm\\n337802               , hr.confidence as hr_sensor_confidence\\n337803               , abs(round(hr.timestamp) - round(gps.timestamp)) as dif\\n337804          from gps as gps\\n337805          LEFT JOIN\\n337806               heartrate as hr\\n337807          ON   dhms(datepart(gps.timestamp), hour(gps.timestamp), minute(gps.timestamp), 0)\\n337808             = dhms(datepart(hr.timestamp), hour(hr.timestamp), minute(hr.timestamp), 0)\\n337809          where    timepart(hr.timestamp) BETWEEN '8:30't AND '16:00't\\n337810                OR datepart(gps.timestamp) IN ('27JAN2024'd, '28JAN2024'd)\\n337811          group by calculated timestamp\\n337812          having dif = min(dif)\\n337813      ;\\nNOTE: The query requires remerging summary statistics back with the original data.\\nNOTE: Invalid (or missing) arguments to the ROUND function have caused the function to return a missing value.\\nNOTE: Invalid (or missing) arguments to the ABS function have caused the function to return a missing value.\\nNOTE: Invalid (or missing) arguments to the TIMEPART function have caused the function to return a missing value.\\nNOTE: Table WORK._SNOWBOARDING_GPS_HR created, with 12817 rows and 8 columns.\\n\\n337814  quit;\\nNOTE: PROCEDURE SQL used (Total process time):\\n      real time           0.06 seconds\\n      cpu time            0.09 seconds\\n      \\n\\n337815  \\n337816  \\n337817  ods html5 (id=saspy_internal) close;ods listing;\\n337818  \\n\\n\",\n",
       " 'LST': ''}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sas.submit(code=\n",
    "'''\n",
    "\n",
    "/* Fuzzy merge GPS with heartrate data */\n",
    "proc sql;\n",
    "    create table _snowboarding_gps_hr(drop=dif) as\n",
    "        select round(gps.timestamp) as timestamp format=datetime.2\n",
    "             , datepart(gps.timestamp) as date format=date9.\n",
    "             , gps.lat\n",
    "             , gps.lon\n",
    "             , round(gps.elevation)*3.28084 as elevation\n",
    "             , round(gps.speed, .1) as speed\n",
    "             , hr.bpm\n",
    "             , hr.confidence as hr_sensor_confidence\n",
    "             , abs(round(hr.timestamp) - round(gps.timestamp)) as dif\n",
    "        from gps as gps\n",
    "        LEFT JOIN\n",
    "             heartrate as hr\n",
    "        ON   dhms(datepart(gps.timestamp), hour(gps.timestamp), minute(gps.timestamp), 0)\n",
    "           = dhms(datepart(hr.timestamp), hour(hr.timestamp), minute(hr.timestamp), 0)\n",
    "        where    timepart(hr.timestamp) BETWEEN '8:30't AND '16:00't\n",
    "              OR datepart(gps.timestamp) IN ('27JAN2024'd, '28JAN2024'd)\n",
    "        group by calculated timestamp\n",
    "        having dif = min(dif)\n",
    "    ;\n",
    "quit;\n",
    "\n",
    "'''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LOG': \"337819  ods listing close;ods html5 (id=saspy_internal) options(bitmap_mode='inline') device=svg style=HTMLBlue; ods graphics on /\\n337819! outputfmt=png;\\nNOTE: Writing HTML5(SASPY_INTERNAL) Body file: sashtml6.htm\\n337820  \\n337821  \\n337822  \\n337823  /* Add in types: lift or run */\\n337824  proc sql;\\n337825      create table snowboarding_gps_hr as\\n337826          select gps.*\\n337827                 , meta.type\\n337828                 , CASE(meta.type)\\n337829                       when('Lift') then meta.nbr\\n337830                       else .\\n337831                   END as lift_nbr\\n337832                 , CASE(meta.type)\\n337833                       when('Run') then meta.nbr\\n337834                       else .\\n337835                   END as run_nbr\\n337836          from _snowboarding_gps_hr as gps\\n337837          LEFT JOIN\\n337838               gps_meta as meta\\n337839          ON gps.timestamp BETWEEN meta.start AND meta.end\\n337840          order by gps.timestamp\\n337841      ;\\nNOTE: The execution of this query involves performing one or more Cartesian product joins that can not be optimized.\\nNOTE: Table WORK.SNOWBOARDING_GPS_HR created, with 12817 rows and 11 columns.\\n\\n337842  quit;\\nNOTE: PROCEDURE SQL used (Total process time):\\n      real time           0.05 seconds\\n      cpu time            0.06 seconds\\n      \\n\\n337843  \\n337844  /* De-dupe timestamps */\\n337845  proc sort data=snowboarding_gps_hr nodupkey;\\n337846      by timestamp;\\n337847  run;\\n\\nNOTE: There were 12817 observations read from the data set WORK.SNOWBOARDING_GPS_HR.\\nNOTE: 175 observations with duplicate key values were deleted.\\nNOTE: The data set WORK.SNOWBOARDING_GPS_HR has 12642 observations and 11 variables.\\nNOTE: PROCEDURE SORT used (Total process time):\\n      real time           0.00 seconds\\n      cpu time            0.00 seconds\\n      \\n\\n337848  \\n337849  \\n337850  ods html5 (id=saspy_internal) close;ods listing;\\n337851  \\n\\n\",\n",
       " 'LST': ''}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sas.submit(code=\n",
    "'''\n",
    "\n",
    "/* Add in types: lift or run */\n",
    "proc sql;\n",
    "    create table snowboarding_gps_hr as\n",
    "        select gps.*\n",
    "               , meta.type\n",
    "               , CASE(meta.type)\n",
    "                     when('Lift') then meta.nbr\n",
    "                     else .\n",
    "                 END as lift_nbr\n",
    "               , CASE(meta.type)\n",
    "                     when('Run') then meta.nbr\n",
    "                     else .\n",
    "                 END as run_nbr\n",
    "        from _snowboarding_gps_hr as gps\n",
    "        LEFT JOIN\n",
    "             gps_meta as meta\n",
    "        ON gps.timestamp BETWEEN meta.start AND meta.end\n",
    "        order by gps.timestamp\n",
    "    ;\n",
    "quit;\n",
    "\n",
    "/* De-dupe timestamps */\n",
    "proc sort data=snowboarding_gps_hr nodupkey;\n",
    "    by timestamp;\n",
    "run;\n",
    "\n",
    "'''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LOG': '337852  ods listing close;ods html5 (id=saspy_internal) options(bitmap_mode=\\'inline\\') device=svg style=HTMLBlue; ods graphics on /\\n337852! outputfmt=png;\\nNOTE: Writing HTML5(SASPY_INTERNAL) Body file: sashtml7.htm\\n337853  \\n337854  \\n337855  \\n337856  cas;\\nNOTE: The session name identified with the SESSREF= SAS option is connected to Cloud Analytic Services. The default value for \\n      SESSREF= is CASAUTO.\\n337857  caslib _ALL_ assign;\\nNOTE: A SAS Library associated with a caslib can only reference library member names that conform to SAS Library naming conventions.\\nNOTE: CASLIB AIoTPgMeta for session CASAUTO will not be mapped to SAS Library AIoTPgMeta. The CASLIB name is not valid for use as a \\n      libref.\\nNOTE: CASLIB ALC for session CASAUTO will be mapped to SAS Library ALC.\\nNOTE: CASLIB AO_REF for session CASAUTO will be mapped to SAS Library AO_REF.\\nNOTE: CASLIB AO_RES for session CASAUTO will be mapped to SAS Library AO_RES.\\nNOTE: CASLIB CASUSER(Stu.Sztukowski@sas.com) for session CASAUTO will be mapped to SAS Library CASUSER.\\nNOTE: CASLIB DataVizGallery for session CASAUTO will not be mapped to SAS Library DataVizGallery. The CASLIB name is not valid for \\n      use as a libref.\\nNOTE: CASLIB Formats for session CASAUTO will be mapped to SAS Library FORMATS.\\nNOTE: CASLIB GTPPub for session CASAUTO will be mapped to SAS Library GTPPUB.\\nNOTE: CASLIB ModelPerformanceData for session CASAUTO will not be mapped to SAS Library ModelPerformanceData. The CASLIB name is \\n      not valid for use as a libref.\\nNOTE: CASLIB Models for session CASAUTO will be mapped to SAS Library MODELS.\\nNOTE: CASLIB Public for session CASAUTO will be mapped to SAS Library PUBLIC.\\nNOTE: CASLIB QASANLOUT for session CASAUTO will not be mapped to SAS Library QASANLOUT. The CASLIB name is not valid for use as a \\n      libref.\\nNOTE: CASLIB QASMartStore for session CASAUTO will not be mapped to SAS Library QASMartStore. The CASLIB name is not valid for use \\n      as a libref.\\nNOTE: CASLIB RiskIT for session CASAUTO will be mapped to SAS Library RISKIT.\\nNOTE: CASLIB Samples for session CASAUTO will be mapped to SAS Library SAMPLES.\\nNOTE: CASLIB cabrazil for session CASAUTO will be mapped to SAS Library CABRAZIL.\\nNOTE: CASLIB cpggroc for session CASAUTO will be mapped to SAS Library CPGGROC.\\nNOTE: CASLIB cpgretl for session CASAUTO will be mapped to SAS Library CPGRETL.\\nNOTE: CASLIB doe_psd for session CASAUTO will be mapped to SAS Library DOE_PSD.\\n337858  \\n337859  /* Load, promote and save to CAS */\\n337860  proc casutil incaslib=\\'casuser\\' outcaslib=\\'casuser\\';\\nNOTE: The UUID \\'ef886493-f15c-8b43-a5b9-ce0c7c7a8b08\\' is connected using session CASAUTO.\\n337861      droptable casdata=\\'snowboarding_gps_hr\\' quiet;\\nNOTE: The Cloud Analytic Services server processed the request in 0.000274 seconds.\\n337862      load data=snowboarding_gps_hr promote;\\nNOTE: The INCASLIB= option is ignored when using the DATA= option in the LOAD statement.\\nNOTE: WORK.SNOWBOARDING_GPS_HR was successfully added to the \"CASUSER(Stu.Sztukowski@sas.com)\" caslib as \"SNOWBOARDING_GPS_HR\".\\n337863      droptable casdata=\\'gps_meta\\' quiet;\\nNOTE: The Cloud Analytic Services server processed the request in 0.000228 seconds.\\n337864      load data=gps_meta promote;\\nNOTE: The INCASLIB= option is ignored when using the DATA= option in the LOAD statement.\\nNOTE: WORK.GPS_META was successfully added to the \"CASUSER(Stu.Sztukowski@sas.com)\" caslib as \"GPS_META\".\\n337865  \\n337866      save casdata=\\'snowboarding_gps_hr\\' replace;\\nNOTE: Cloud Analytic Services saved the file snowboarding_gps_hr.sashdat in caslib CASUSER(Stu.Sztukowski@sas.com).\\nNOTE: The Cloud Analytic Services server processed the request in 0.017728 seconds.\\n337867      save casdata=\\'gps_meta\\' replace;\\nNOTE: Cloud Analytic Services saved the file gps_meta.sashdat in caslib CASUSER(Stu.Sztukowski@sas.com).\\nNOTE: The Cloud Analytic Services server processed the request in 0.008091 seconds.\\n337868  quit;\\n\\nNOTE: PROCEDURE CASUTIL used (Total process time):\\n      real time           0.04 seconds\\n      cpu time            0.01 seconds\\n      \\n\\n337869  \\n337870  \\n337871  \\n337872  ods html5 (id=saspy_internal) close;ods listing;\\n337873  \\n\\n',\n",
       " 'LST': ''}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sas.submit(code=\n",
    "'''\n",
    "\n",
    "cas;\n",
    "caslib _ALL_ assign;\n",
    "\n",
    "/* Load, promote and save to CAS */\n",
    "proc casutil incaslib='casuser' outcaslib='casuser';\n",
    "    droptable casdata='snowboarding_gps_hr' quiet;\n",
    "    load data=snowboarding_gps_hr promote;\n",
    "    droptable casdata='gps_meta' quiet;\n",
    "    load data=gps_meta promote;\n",
    "\n",
    "    save casdata='snowboarding_gps_hr' replace;\n",
    "    save casdata='gps_meta' replace;\n",
    "quit;\n",
    "\n",
    "'''\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
